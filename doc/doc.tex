\documentclass[letterpaper,12pt]{article}

\usepackage{times}
\usepackage{graphicx,color}
\usepackage{amsmath,amssymb,verbatim}
\usepackage{ulem}
\usepackage{hyperref}
\usepackage{multirow}
\usepackage{hhline}
\usepackage{makecell}
\usepackage{xspace}
\usepackage{url}

\setlength{\hoffset}{0in}
\setlength{\voffset}{0in}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\setlength{\topmargin}{0in}
\setlength{\headheight}{0in}
\setlength{\headsep}{0in}
\setlength{\textwidth}{6.5in}
\setlength{\textheight}{9in}
\setlength{\marginparsep}{0pt}
\setlength{\marginparwidth}{0pt}
\setlength{\parskip}{9pt}
\setlength{\parindent}{0pt}

\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\openec}{{\sf\small OpenEC}\xspace}
\renewcommand{\ttdefault}{cmtt}

\title{{\bf OpenEC User Guide}}
\author{ADSLab @ CUHK}
\date{Release: Feb 2019\\}

\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents

\clearpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% introduction

\section{Preparation}
\label{sec:installation}

We have tested \openec in Ubuntu 14.04. Please create a user called {\sl openec} and
install some prerequisite libraries listed below.

\begin{itemize}

\item cmake v3.1 or higher

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo apt-get install cmake} 
}%
}
\end{center}

\item g++ v4.8.4

We need a C++ compiler that supports the C++11 standard.

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo apt-get install g++}
}%
}
\end{center}

\item redis v3.2.8 or higher

Download {\bf redis-3.2.8.tar.gz} and install it.

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt tar -zxvf redis-3.2.8.tar.gz} \\
\$ {\tt cd redis-3.2.8} \\
\$ {\tt make} \\
\$ {\tt sudo make install}
}%
}
\end{center}

Install redis as a background daemon. You can just use the default settings

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt cd utils} \\
\$ {\tt sudo ./install\_server.sh}
}%
}
\end{center}

Configure redis to be remotely accessible.
%

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo service redis\_6379 stop}
}%
}
\end{center}

Edit {\sl /etc/redis/6379.conf}. Find the line with {\em bind 127.0.0.0}
and modify it to {\em bind 0.0.0.0}, then start redis.

%
\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo service redis\_6379 start}
}%
}
\end{center}

\item hiredis

Download {\bf hiredis.tar.gz} and install it.

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt tar -zxvf hiredis.tar.gz} \\
\$ {\tt cd hiredis} \\
\$ {\tt make} \\
\$ {\tt sudo make install} 
}%
}
\end{center}

\item gf-complete v1.03

Download {\bf gf-complete.tar.gz} and install it (note that you may need to
install {\sf autoconf} and {\sf libtool} first).

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt tar -zxvf gf-complete.tar.gz} \\
\$ {\tt cd gf-complete} \\
\$ {\tt ./autogen.sh} \\
\$ {\tt ./configure} \\
\$ {\tt make} \\
\$ {\tt sudo make install}
}%
}
\end{center}

\item ISA-L v2.14.0

Download {\bf isa-l-2.14.0.tar.gz} and install it (note that you may need to install
{\sf yasm} which is required by isa-l first).

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt tar -zxvf isa-l-2.14.0.tar.gz} \\
\$ {\tt cd isa-l-2.14.0} \\
\$ {\tt ./autogen.sh} \\
\$ {\tt ./configure} \\
\$ {\tt make} \\
\$ {\tt sudo make install}
}%
}
\end{center}
	
\end{itemize}

\openec now supports running atop HDFS3, HDFS-RAID and QFS. We need to deploy
one DSS among the three to try out \openec. (We can choose any one section
from \S\ref{sec:hdfs3}, \S\ref{sec:hdfsraid} and \S\ref{sec:qfs} for a reference
to deploy DSS and skip the other two.)

\section{OpenEC with HDFS3}
\label{sec:hdfs3}

In this section, we explain how to deploy \openec with HDFS3.

\subsection{Prerequisite}

The following packages need to be first installed.

\begin{itemize}


\item maven v3.5.0 or higher

Download {\bf apache-maven-3.5.0-bin.tar.gz}.

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt tar -zxvf apache-maven-3.5.0-bin.tar.gz}
}%
}
\end{center}

Set the environment variables {\tt M2\_HOME} and {\tt PATH} (you may need to
set {\tt MVN\_OPTS} if you are behind a proxy.)

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
{\tt export M2\_HOME=\path{~/apache-maven-3.5.0}} \\
{\tt export PATH=\$PATH:\$M2\_HOME/bin} 
}%
}
\end{center}



\item java8

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo add-apt-repository ppa:webupd8team/java} \\
\$ {\tt sudo apt-get update} \\
\$ {\tt sudo apt-get install oracle-java8-installer} \\
\$ {\tt sudo apt-get install oracle-java8-set-default}
}%
}
\end{center}

Set the environment variable {\tt JAVA\_HOME}.

\end{itemize}

\subsection{Install HDFS3 with OpenEC Integrations}
Please download {\bf hadoop-3.0.0-src.tar.gz} (we provided a copy on our project website)
to the home directory of user {\sl openec} and extract source code from the tarball.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt tar -zxvf hadoop-3.0.0-src.tar.gz} 
}%
}
\end{center}

We now configure system variables for HDFS3. It is recommended to include the following
configuration in your \path{~/.bashrc}.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
{\tt export HADOOP\_SRC\_DIR=/home/openec/hadoop-3.0.0-src} \\
{\tt export HADOOP\_HOME=\${HADOOP\_SRC\_DIR}/hadoop-dist/target/hadoop-3.0.0} \\
{\tt export PATH=\${HADOOP\_HOME}/bin:\${HADOOP\_HOME}/sbin:\${PATH}} \\
{\tt export HADOOP\_CLASSPATH=\${JAVA\_HOME}/lib/tools.jar:\${HADOOP\_CLASSPATH}} \\
{\tt export CLASSPATH=\$JAVA\_HOME/lib:\$CLASSPATH} \\
{\tt export LD\_LIBRARY\_PATH=\$HADOOP\_HOME/lib/native:\${JAVA\_HOME}/jre/lib/\\amd64/server/:/usr/local/lib:\$LD\_LIBRARY\_PATH}
}% 
}
\end{center}

Please download {\bf OpenEC-v1.0.tar.gz} from our project website to the home directory of user {\sl openec}
and extract source code from the tarball. Now we can install integrations into HDFS3 by running
the script {\sl install.sh}, which will also compile the modified source code of HDFS3.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt tar -zxvf OpenEC-v1.0.tar.gz} \\
\$ {\tt cd OpenEC-v1.0/hdfs3-integration} \\
\$ {\tt ./install.sh}
}% 
}
\end{center}

Please run the following commands to compile \openec for HDFS3.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt cd OpenEC-v1.0} \\
\$ {\tt cmake . -DFS\_TYPE:STRING=HDFS3} \\
\$ {\tt make}
}% 
}
\end{center}

\subsection{Example Architecture}

Table~\ref{tab:hdfs3arch} shows an example architecture for our HDFS3 integration.
Basically, \openec controller runs in the same node as the NameNode of HDFS3.
And each HDFS3 DataNode co-locates with an \openec agent. Please distribute
the working directory (\path{~/hadoop-3.0.0-src} and \path{~/OpenEC-v1.0}) to all 
the nodes.

\begin{table}[h]
\centering
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
IP & HDFS3 & OpenEC \\
\hline
\hline
192.168.0.1 & NameNode & Controller \\
\hline
192.168.0.2 & DataNode & Agent \\
\hline
192.168.0.3 & DataNode & Agent \\
\hline
192.168.0.4 & DataNode & Agent \\
\hline
192.168.0.5 & DataNode & Agent \\
\hline
\end{tabular}
\vspace{-3pt}
\caption{Example architecture for HDFS3 integration}
\label{tab:hdfs3arch}
\end{table}

\subsection{HDFS3 Configuration}

We provide sample configuration files under \path{OpenEC-v1.0/hdfs3-integration/conf} for HDFS3.
We explain some fields that are related to \openec integrations here and you may leave other fields
to be the same as our sample configurations. You can copy our samples to \path{HADOOP\_HOME/etc/hadoop}
and configure your HDFS3 there. Please distribute your configuration files to all the nodes.

\begin{itemize}

\item hadoop-env.sh:

\begin{center}
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
JAVA\_HOME & - & \makecell[l]{Path to java installation. \\e.g. \path{/usr/lib/jvm/java-8-oracle}} \\
\hline
HADOOP\_CLASSPATH & \makecell[l]{\$HADOOP\_HOME/oeclib/*:\\ \$JAVA\_HOME/lib*} & Path to OpenEC and java libraries. \\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\item core-site.xml:

\begin{center}
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
fs.defaultFS & hdfs://192.168.0.1:9000 & NameNode configuration. \\
\hline
hadoop.tmp.dir & \makecell[l]{/home/openec/hadoop-3.0.0-src/hadoop-dist/\\target/hadoop-3.0.0} & Base directory for hdfs3 temporary directories.\\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\item hdfs-site.xml:

\begin{center}
\centering
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
dfs.replication & 1 & Replication factor of HDFS. \\
\hline
dfs.blocksize & 1048576 & The size of a block in bytes. \\
\hline
dfs.block.replicator.classname & \makecell[l]{org.apache.hadoop.hdfs.server.\\blockmanagement.\\BlockPlacementPolicyOEC} & \openec placement integartion. \\
\hline
link.oec & true & \makecell[l]{true: Run HDFS3 with \openec. \\ false: Run HDFS3 without \openec.} \\
\hline
oec.controller.addr & 192.168.0.1 & IP address of \openec controller. \\
\hline
oec.local.addr & - & IP address of a node itself. \\
\hline
oec.pktsize & 131072 & The size of a packet in \openec. \\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\item workers:

\begin{center}
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|}
\hline
192.168.0.2\\
\hline
192.168.0.3\\
\hline
192.168.0.4\\
\hline
192.168.0.5\\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\end{itemize}

To start HDFS3, we can run the following command in NameNode.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt hdfs namenode -format} \\
\$ {\tt start-dfs.sh}
}% 
}
\end{center}

\section{OpenEC with HDFS-RAID}
\label{sec:hdfsraid}

In this section, we show how to deploy \openec with HDFS-RAID.

\subsection{Prerequisite}

The following packages need first to be installed.

\begin{itemize}

\item ant  

Download {\bf apache-ant-1.9.13-bin.tar.gz}.

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt tar -zxvf apache-ant-1.9.13.-bin.tar.gz}
}%
}
\end{center}

Set the environment variables {\tt ANT\_HOME} and {\tt PATH} (you may need to
set {\tt ANT\_OPTS} if you are behind a proxy.)

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
{\tt export ANT\_HOME=\path{~/apache-ant-1.9.13}} \\
{\tt export PATH=\$PATH:\$ANT\_HOME/bin}
}%
}
\end{center}

\item java8

If you have installed java8, please skip this step.

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo add-apt-repository ppa:webupd8team/java} \\
\$ {\tt sudo apt-get update} \\
\$ {\tt sudo apt-get install oracle-java8-installer} \\
\$ {\tt sudo apt-get install oracle-java8-set-default}
}%
}
\end{center}

Set the environment variable {\tt JAVA\_HOME}.

\end{itemize}

\subsection{Install HDFS-RAID with OpenEC Integrations}

Please download {\bf hadoop-20.tar.gz} (we provided a copy on our project website).

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt tar -zxvf hadoop-20.tar.gz}
}%
}
\end{center}

We now configure system variables for HDFS-RAID. It is recommended to include the following
configuration in your \path{~/.bashrc}.

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
{\tt export HADOOP\_HOME=/home/openec/hadoop-20} \\
{\tt export PATH=\$HADOOP\_HOME/bin:\$HADOOP\_HOME/sbin:\$PATH} \\
{\tt export HADOOP\_CLASSPATH=\${JAVA\_HOME}/lib/tools.jar:\$HADOOP\_CLASSPATH} \\
{\tt export CLASSPATH=\$JAVA\_HOME/lib:\$CLASSPATH} \\
{\tt export LD\_LIBRARY\_PATH=\$HADOOP\_HOME/lib/native:\${JAVA\_HOME}/jre/lib/ \\ amd64/server/:/usr/local/lib:\$LD\_LIBRARY\_PATH}
}%
}
\end{center}

Please download {\bf OpenEC-v1.0.tar.gz} from our project website to the home directory of user {\sl openec}
and extract source code from the tarball. Now we can install integrations into HDFS-RAID by running
the script install.sh, which will also compile the modified source code of HDFS-RAID.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt tar -zxvf OpenEC-v1.0.tar.gz} \\
\$ {\tt cd OpenEC-v1.0/hdfs3-integration} \\
\$ {\tt ./install.sh}
}% 
}
\end{center}

We now compile the source code of \openec. Please run the following commands.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt cd OpenEC-v1.0} \\
\$ {\tt cmake . -DFS\_TYPE:STRING=HDFSRAID} \\
\$ {\tt make}
}% 
}
\end{center}

\subsection{Example Architecture}

Table~\ref{tab:hdfsraidarch} shows an example architecture for our HDFS-RAID integration.
Basically, \openec controller runs in the same node as the NameNode of HDFS-RAID.
And each HDFS-RAID DataNode co-locates with an \openec agent. Please distribute
the working directory (\path{~/hadoop-20} and \path{~/OpenEC-v1.0}) to all 
the nodes.

\begin{table}[h]
\centering
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
IP & HDFS-RAID & OpenEC \\
\hline
\hline
192.168.0.1 & NameNode & Controller \\
\hline
192.168.0.2 & DataNode & Agent \\
\hline
192.168.0.3 & DataNode & Agent \\
\hline
192.168.0.4 & DataNode & Agent \\
\hline
192.168.0.5 & DataNode & Agent \\
\hline
\end{tabular}
\vspace{-3pt}
\caption{Example architecture for HDFS-RAID integration}
\label{tab:hdfsraidarch}
\end{table}

\subsection{HDFS-RAID Configuration}

We provide sample configuration files for HDFS-RAID under \path{OpenEC-v1.0/hdfsraid-integration/conf}.
We explain some of the fields here in detail and other fields can be set to be the same as our
samples. Please copy our sample configuration files to \path{HADOOP\_HOME/conf} and configure your
HDFS-RAID. Then distribute configuration files to all the nodes. 

\begin{itemize}

\item hadoop-env.sh:

\begin{center}
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
JAVA\_HOME & - & \makecell[l]{Path to java installation. \\ e.g. \path{/usr/lib/jvm/java-8-oracle}} \\
\hline
HADOOP\_CLASSPATH & \makecell[l]{\$HADOOP\_HOME/oeclib/*:\\ \$JAVA\_HOME/lib*} & \makecell[l]{Path to OpenEC and java libraries.} \\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\item core-site.xml: 

\begin{center}
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
fs.default.name & hdfs://192.168.0.1:9000 & NameNode configuration. \\
\hline
hadoop.tmp.dir & \makecell[l]{/home/openec/hadoop-20/tmp} & Base directory for HDFS-RAID temporary directories.\\
\hline
topology.script.file.name & - & Path to rackAware.sh \\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\item hdfs-site.xml:

\begin{center}
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
dfs.http.address & 192.168.0.1:50070 & HTTP address of NameNode \\
\hline
dfs.replication & 1 & Replication factor of HDFS-RAID. \\
\hline
dfs.block.size & 1048576 & The size of a block in bytes. \\
\hline
dfs.block.replicator.classname & \makecell[l]{org.apache.hadoop.hdfs.server.\\namenode.BlockPlacementPolicyOEC} & \openec placement class. \\
\hline
link.oec & true & Run HDFS-RAID with \openec. \\
\hline
oec.controller.addr & 192.168.0.1 & IP address of \openec controller. \\
\hline
oec.local.addr & - & IP address of a node itself. \\
\hline
oec.pktsize & 131072 & The size of a packet in \openec. \\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\item masters:

\begin{center}
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|}
\hline
192.168.0.1 \\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\item slaves:

\begin{center}
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|}
\hline
192.168.0.2 \\
\hline
192.168.0.3 \\
\hline
192.168.0.4 \\
\hline
192.168.0.5 \\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\end{itemize}

To start HDFS-RAID, we can run the following command in NameNode.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt hadoop namenode -format} \\
\$ {\tt start-dfs.sh}
}% 
}
\end{center}

\section{OpenEC with QFS}
\label{sec:qfs}

\subsection{Prerequisite}

The following packages need first to be installed.

\begin{itemize}

\item libboost-regex-dev 1.3.4 or higher

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo apt-get install libboost-regex-dev}
}%
}
\end{center}

\item libkrb5-dev

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo apt-get install libkrb5-dev}
}%
}
\end{center}

\item xfslibs-dev

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo apt-get install xfslibs-dev}
}%
}
\end{center}

\item libssl-dev

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo apt-get install libssl-dev}
}%
}
\end{center}

\item python-dev

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo apt-get install python-dev}
}%
}
\end{center}

\item libfuse-dev

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt sudo apt-get install libfuse-dev}
}%
}
\end{center}

\end{itemize}

\subsection{Install QFS with OpenEC Integrations}

Please download {\bf qfs-v2.1.1.tar.gz}. We provide a copy in our project website.

\begin{center}
\noindent\fbox{%
\parbox{400pt}{%
\$ {\tt tar -zxvf qfs-2.1.1.tar.gz}
}%
}
\end{center}

We now configure system variables for QFS. It is recommended to include the
following configuration in your \path{~/.bashrc}.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
{\tt export export QFS\_HOME=/home/openec/qfs} \\
{\tt export PATH=\${QFS\_HOME}/build/release/bin:\${PATH}}
}% 
}
\end{center}

Please download OpenEC-v1.0.tar.gz from our project website to the home directory of user openec
and extract source code from the tarball. Now we can install integrations into QFS by
running the script install.sh, which will also compile the modified source code of QFS.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt tar -zxvf OpenEC-v1.0.tar.gz} \\
\$ {\tt cd OpenEC-v1.0/qfs-integration} \\
\$ {\tt ./install.sh}
}% 
}
\end{center}

We now compile the source code of OpenEC . Please run the following commands.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt cd OpenEC-v1.0} \\
\$ {\tt cmake . -DFS\_TYPE:STRING=QFS} \\
\$ {\tt make}
}% 
}
\end{center}

\subsection{Example Architecture}

Table~\ref{tab:qfsarch} shows an example architecture for our QFS integration.
Basically, \openec controller runs in the same node as the metaserver of QFS.
And each QFS chunkserver co-locates with an \openec agent. Please distribute
the working directory (\path{~/qfs} and \path{~/OpenEC-v1.0}) to all 
the nodes.

\begin{table}[h]
\centering
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
IP & QFS & OpenEC \\
\hline
\hline
192.168.0.1 & Metaserver & Controller \\
\hline
192.168.0.2 & Chunkserver & Agent \\
\hline
192.168.0.3 & Chunkserver & Agent \\
\hline
192.168.0.4 & Chunkserver & Agent \\
\hline
192.168.0.5 & Chunkserver & Agent \\
\hline
\end{tabular}
\vspace{-3pt}
\caption{Example architecture for QFS integration}
\label{tab:qfsarch}
\end{table}

\subsection{QFS Configuration}

We also provide sample configuration files for QFS. We explain some of the fields in detail and 
other fields can be set to be the same as we provided in the samples. Please configure your QFS
based on our samples.

\begin{itemize}

\item MetaServer.conf:

\begin{center}
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
metaServer.clientPort & 20000 & \makecell[l]{Port number for metaserver to communicate with clients.}\\
\hline
metaServer.chunkServerPort & 30000 & \makecell[l]{Port number for metaserver to communicate with chunkserver.} \\
\hline
metaServer.logDir & - & \makecell[l]{Directory for the log of metaserver.} \\
\hline
metaServer.cpDir & - & \makecell[l]{Directory for the checkpoint of metaserver.} \\
\hline
openec.useoec & true & \makecell[l]{true: enable OpenEC integrations. \\false; disable OpenEC integrations.} \\
\hline
openec.localip & - &  \\
\hline
openec.coorip & 192.168.0.1 & \makecell[l]{IP address of OpenEC controller.} \\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\item ChunkServer.conf:

\begin{center}
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
chunkServer.metaServer.hostname & 192.168.0.1 & \makecell[l]{IP address of metaserver.} \\
\hline
chunkServer.metaServer.port & 30000 & \makecell[l]{Port number for metaserver to communicate with chunkserver.} \\
\hline
chunkServer.clientPort & 22000 & \makecell[l]{Port number for chunkserver to communicate with clients.} \\
\hline
chunkServer.chunkDir & - & \makecell[l]{Directory for chunkserver to store chunks.} \\
\hline
chunkServer.pidFile & - & \makecell[l]{File to store pid of chunkserver} \\
\hline
openec.useoec & true & \makecell[l]{true: enable OpenEC integrations. \\false; disable OpenEC integrations.} \\
\hline
openec.localip & - &  \\
\hline
openec.coorip & 192.168.0.1 & \makecell[l]{IP address of OpenEC controller.} \\
\hline
\end{tabular}
\vspace{-3pt}
\end{center}

\end{itemize}

To start metaserver, please run the following command:

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt metaserver MetaServer.conf}
}% 
}
\end{center}

To start chunkserver, please run the following command:

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt chunkserver ChunkServer.conf}
}% 
}
\end{center}



\section{OpenEC Configuration}

We provide sample configuration file for \openec under \path{OpenEC-v1.0/conf}.
Table~\ref{tab:sysSetting} explains the default configuration provided in our sample.
Table~\ref{tab:ecpolicy} and Table~\ref{tab:offlinepool} show the configuration of an
erasure code and an offline encoding pool.

\begin{table}[h]
\centering
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
controller.address & 192.168.0.1 & IP address of controller. \\
\hline
agents.address & \makecell[l]{/default/192.168.0.2 \\ /default/192.168.0.3 \\ /default/192.168.0.4 \\ /default/192.168.0.5} & \makecell[l]{A list of IP addresses of all agents, in the form of {\sl zone/IP}, \\where {\sl zone} denotes the zone (e.g. rack or datacenter).} \\
\hline
local.address & - & IP address of a node itself. \\ 
\hline
packet.size & 131072 & The size of a packet. \\
\hline
dss.type & - & \makecell[l]{Type of DSS. Please choose from {\sl HDFS3}, {\sl HDFSRAID} and {\sl QFS}}. \\
\hline
dss.parameter & - & \makecell[l]{IP and port of DSS for client access. e.g. {\sl 192.168.0.1, 9000} \\for HDFS3.} \\
\hline
ec.policy & & Table~\ref{tab:ecpolicy}\\
\hline
offline.pool & & Table~\ref{tab:offlinepool}\\
\hline
\end{tabular}
\vspace{-3pt}
\caption{sysSetting.xml for \openec}
\label{tab:sysSetting}
\end{table}

\begin{table}[h]
\centering
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
ecid & rs\_4\_3 & Unique id for an erasure code. \\
\hline
class & RSCONV & Class name of erasure code implementation. \\
\hline
n & 4 & Parameter N for the erasure code. \\ 
\hline
k & 3 & Parameter K for the erasure code. \\
\hline
w & 1 & Parameter W for the erasure code. \\
\hline
opt & -1 & \makecell[l]{Optimization level for \openec. Four levels of optimization is provided \\by \openec, including -1, 0, 1, 2. -1: no optimization are enabled. \\0: BindX is enabled. 1: BindX and BindY are enabled. 2: Hierarchial \\awareness is enabled.} \\
\hline
\end{tabular}
\vspace{-3pt}
\caption{ec.policy configuration}
\label{tab:ecpolicy}
\end{table}

\begin{table}[h]
\centering
\footnotesize
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{|l|l|l|}
\hline
Field & Default & Description \\
\hline
\hline
poolid & rs\_4\_3\_pool & Unique id for an offline encoding pool. \\
\hline
ecid & rs\_4\_3 & Erasure code that is applied for the pool. \\
\hline
base & 1 & Block size (in MiB) for the pool, which is no larger than the block size in HDFS3. \\ 
\hline
\end{tabular}
\vspace{-3pt}
\caption{offline.pool configuration}
\label{tab:offlinepool}
\end{table}

To start \openec, we can run the following command in controller:

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt cd OpenEC-v1.0} \\
\$ {\tt python script/start.py}
}% 
}
\end{center}

\section{Basic Operations}

\openec supports four basic operations, including {\sl write}, {\sl read}, {\sl normal read} and
{\sl full-node recovery}. We now show how to perform these basic operations. 

\subsection{Write}

OECClient supports two mode to write a file into DSS, including writing a file with online encoding
enabled on the writing path and writing a file into an offline encoding pool, in which a coding group
is organized and encoded offline.

We show the usage and command line example to write a file (called {\sl input}) of 
size 3\,MiB and store it as {\sl /testfile1} with online encoding enabled. The erasure code 
for online encoding is {\sl rs\_4\_3}, which is configured in sysSetting.xml.
Please note that this command should run in a node that holds an Agent.

Usage:
\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
{\tt ./OECClient write [inputfile] [saveas] [ecid] online [sizeinMB]}
}% 
}
\end{center}

Example:
\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt ./OECClient write input /testfile1 rs\_4\_3 online 3} 
}% 
}
\end{center}

We now show how to apply offline encoding. We first write the file into our offline encoding pool.
The example command line in the following box shows that we write the file ({\sl input}) and store
it as {\sl /testfile2}. The offline encoding pool is {\sl rs\_4\_3\_pool}, which is configured in sysSetting.xml.
Please note that this command should also run in a node that holds an Agent.

Usage:
\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
{\tt ./OECClient write [inputfile] [saveas] [poolid] offline [sizeinMB]} 
}% 
}
\end{center}

Example:
\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt ./OECClient write input /testfile2 rs\_4\_3\_pool offline 3} 
}% 
}
\end{center}

We then run the following command to instruct \openec start offline encoding.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt ./OECClient startEncode} 
}% 
}
\end{center}

When offline encoding for a coding group finishes, we can check the log of controller ({\sl coor\_output}).
The following line denotes that the offline encoding for a coding group finishes, where {\sl xxxxxx} denotes
the name of the coding group. Note that the name of a coding group is assigned by \openec.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
{\tt offlineEnc for xxxxxx finishes} 
}% 
}
\end{center}


\subsection{Read}

We run OECClient to read a file, including normal read and degraded read. 
The difference between normal read and degraded read is that for degraded read, we
can delete physical blocks in DSS before we run the following command.
Please note that this command should also run in a node that holds an Agent.

Usage:
\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
{\tt ./OECClient read [filename] [saveas]} 
}% 
}
\end{center}

Example:
\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt ./OECClient read /testfile1 output1} \\
\$ {\tt ./OECClient read /testfile2 output2} 
}% 
}
\end{center}

\subsection{Recovery}

For recovery, we can delete physical blocks in DSS and then run the following command to instruct \openec 
to start to repair lost blocks.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
\$ {\tt ./OECClient startRepair} 
}% 
}
\end{center}

We can see the following information in the log of controller, which denotes that \openec finishes repairing a block.
Note that {\sl xxxxxx} is corresponding block name in \openec.

\begin{center}
\noindent\fbox{%
\parbox{420pt}{%
{\tt repair for xxxxxx finishes} 
}% 
}
\end{center}

\section{EC Design in OpenEC}

\end{document}
